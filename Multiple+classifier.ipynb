{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model to learn to classify walking and standing from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is in row column arrangement\n",
      "Rows indicate each instance and each column indicates sensor reading at that instance \n",
      "umber of rows of data 960\n",
      "number of columns of data 6\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "#The following datasets are for training\n",
    "#senor data of walking \n",
    "walking = genfromtxt('./walking-classifier/walking_dataset1.csv', delimiter=',')\n",
    "#senor data of standing\n",
    "standing=genfromtxt('./walking-classifier/standing_dataset1.csv', delimiter=',')\n",
    "\n",
    "\n",
    "#assinging a label of 1 to walking\n",
    "wl=np.ones((len(walking),1))\n",
    "\n",
    "#assinging a label of 0 to standing\n",
    "sl=np.zeros((len(walking),1))\n",
    "\n",
    "#concatenating walking and standing data into a single array to avoid calling functions twice for each of the data sets \n",
    "data=np.vstack((walking[:,1:],standing[:,1:]))\n",
    "print('Data is in row column arrangement')\n",
    "print('Rows indicate each instance and each column indicates sensor reading at that instance ')\n",
    "print('umber of rows of data',data.shape[0])\n",
    "print('number of columns of data',data.shape[1])\n",
    "#concatenating walking and standing lables into a single array\n",
    "labels=np.vstack((wl,sl))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  ,  35.  ,   3.67,  16.5 ,   3.77,  14.  ,   1.63])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walking[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35.  ,   3.67,  16.5 ,   3.77,  14.  ,   1.63],\n",
       "       [ 28.5 ,   3.35,  17.5 ,   3.77,  12.25,   3.9 ],\n",
       "       [ 35.5 ,   2.87,  15.75,   2.86,  17.75,   5.07],\n",
       "       ..., \n",
       "       [ 43.75,   0.83,  14.  ,   0.82,  17.33,   0.47],\n",
       "       [ 43.75,   0.43,  14.25,   0.43,  17.25,   0.83],\n",
       "       [ 44.  ,   0.82,  15.  ,   0.  ,  17.67,   0.47]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model using training data using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model over training dataset is= 99.0625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Training the model with training data sets\n",
    "model = LogisticRegression()\n",
    "model = model.fit(data, labels)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "print('accuracy of the model over training dataset is=',100*model.score(data, labels),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have trained the model using training dataset and accuracy of training is also calculated above .Next Lets check how the model performs on data which the model has not seen during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The following datasets are for testing\n",
    "#importing new and unseen data for walking\n",
    "walking2 = genfromtxt('./walking-classifier/walking_dataset2.csv', delimiter=',')\n",
    "#predicting labels of a unseen data using already trained support vector machine\n",
    "#walking_accuracy=np.sum(clf.predict(walking2[:,1:]))/len(walking2)\n",
    "#print('walking_accuracy=',walking_accuracy*100)\n",
    "#importing new and unseen data for standing\n",
    "standing2 = genfromtxt('./walking-classifier/standing_dataset2.csv', delimiter=',')\n",
    "#predicting labels of a unseen data using already trained support vector machine\n",
    "#standing_accuaracy=1-np.sum(clf.predict(standing2[:,1:]))/len(standing2)\n",
    "#print('standing_accuracy=',standing_accuaracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting labels of testing data from the model learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence for each label on new dataset(standing) is :\n",
      "Note: 1st column indicates confidence of the prediction for standing and second column indicates confidence of prediction for walking\n",
      "99.4\n"
     ]
    }
   ],
   "source": [
    " \n",
    "predicted_labels1 = model.predict(standing2[:,1:])\n",
    "#finding probabilities of prediction\n",
    "prob1 = model.score(standing2[:,1:], np.zeros((len(standing2),1)))\n",
    "#finding confidence of prediction\n",
    "confidence1=100*prob1\n",
    "print('confidence for each label on new dataset(standing) is :')\n",
    "print('Note: 1st column indicates confidence of the prediction for standing and second column indicates confidence of prediction for walking')\n",
    "print(confidence1.round(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of prediction on standing data set = 99.375 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_for_data_set1=1-np.sum(predicted_labels1)/len(predicted_labels1)\n",
    "\n",
    "print('accuracy of prediction on standing data set =',100*accuracy_for_data_set1,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence for each label on new dataset(walking) is :\n",
      "Note: 1st column indicates confidence of the prediction for standing and second column indicates confidence of prediction for walking\n",
      "99.4\n"
     ]
    }
   ],
   "source": [
    "#predicting labels from model \n",
    "predicted_labels2 = model.predict(walking2[:,1:])\n",
    "#finding probabilities of prediction\n",
    "# prob2 = model.predict_proba(walking2[:,1:])\n",
    "prob2 = model.score(walking2[:,1:], np.ones((len(standing2),1)))\n",
    "#finding confidence of prediction\n",
    "confidence2=100*prob2\n",
    "\n",
    "print('confidence for each label on new dataset(walking) is :')\n",
    "print('Note: 1st column indicates confidence of the prediction for standing and second column indicates confidence of prediction for walking')\n",
    "print(confidence2.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of prediction on walking data set = 99.375 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_for_data_set2=np.sum(predicted_labels2)/len(predicted_labels2)\n",
    "print('accuracy of prediction on walking data set =',100*accuracy_for_data_set2,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 7 features per sample; expecting 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4278c29182e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwalking_pred_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalking2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanding2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstanding_pred_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanding2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanding2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Standing accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstanding_pred_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Waliking accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalking_pred_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 317\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 7 features per sample; expecting 6"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "walking_pred_acc = accuracy_score(model.predict(walking2[:,1:]), np.ones((len(standing2),1)))\n",
    "standing_pred_acc = accuracy_score(model.predict(standing2[:, 1:]), np.zeros((len(standing2),1)))\n",
    "print('Standing accuracy', standing_pred_acc)\n",
    "print('Waliking accuracy', walking_pred_acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
